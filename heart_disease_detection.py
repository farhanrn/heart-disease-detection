# -*- coding: utf-8 -*-
"""Heart Disease Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10WgTcscwIArFVZOjI4UzqyFuxIYiTHuw

#<h1 style="font-family: Trebuchet MS; padding: 12px; font-size: 48px; color: #BA1141; text-align: center; line-height: 1.25;"><b>Heart Disease Detection<span style="color: #000000"> EDA & Prediction üîÆ</span></b><br><span style="color: #FF5C8A; font-size: 24px"> </span></h1>
<hr>

# Library and System Configuration
"""

# Pycaret
!pip install pycaret

"""# Library Import üìö"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
import yellowbrick
import pickle
from matplotlib.collections import PathCollection
from statsmodels.graphics.gofplots import qqplot
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, StackingClassifier
from sklearn.metrics import classification_report, accuracy_score
from yellowbrick.classifier import PrecisionRecallCurve, ROCAUC, ConfusionMatrix
from yellowbrick.style import set_palette
from yellowbrick.model_selection import LearningCurve, FeatureImportances
from yellowbrick.contrib.wrapper import wrap

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from pycaret.classification import *
from sklearn.preprocessing import LabelEncoder

# --- Libraries Settings ---
warnings.filterwarnings('ignore')
sns.set_style('whitegrid')
plt.rcParams['figure.dpi']=100
set_palette('dark')

"""# Dataset Configuration ‚è≥"""

!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!rm -rf heart/
!kaggle datasets download -d johnsmith88/heart-disease-dataset -p /content/dataset --unzip

# --- Importing Dataset ---
data = pd.read_csv("/content/dataset/heart.csv")

# --- Reading Dataset ---
data.head()

"""# Dataset Preprocessing üî¶"""

# Checking the missing value of dataframe
print("The Missing Value : ")
data.isna().sum()

# --- Print Dataset Info ---
print('\033[1m'+'.: Dataset Info :.'+'\033[0m')
print('*' * 30)
print('Total Rows:'+'\033[1m', data.shape[0])
print('\033[0m'+'Total Columns:'+'\033[1m', data.shape[1])
print('\033[0m'+'*' * 30)
print('\n')

# --- Print Dataset Detail ---
print('\033[1m'+'.: Dataset Details :.'+'\033[0m')
print('*' * 30)
data.info(memory_usage = False)

data.describe()

"""## <div style="font-family: Trebuchet MS; background-color: #BA1141; color: #FFFFFF; padding: 12px; line-height: 1.5;">Dataset Description üßæ</div>
<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
     There are <mark><b>14 variables</b></mark> in this dataset:
    <ul>
        <li> <b>9 categorical</b> variables, and</li>
        <li> <b>5 continuous</b> variables.</li>
    </ul>
</div>

<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
     The following is the <b>structure of the dataset</b>.<br>
    
<table style="width: 100%">
<thead>
<tr>
<th style="text-align: center; font-weight: bold; font-size:14px;">Variable Name</th>
<th style="text-align: center; font-weight: bold; font-size:14px;">Description</th>
<th style="text-align: center; font-weight: bold; font-size:14px;">Sample Data</th>
</tr>
</thead>
<tbody>
<tr>
<td><b>Age</b></td>
<td>Patient Age <br> (in years)</td>
<td>63; 37; ...</td>
</tr>
<tr>
<td><b>Sex</b></td>
<td>Gender of patient <br> (0 = male; 1 = female)</td>
<td>1; 0; ...</td>
</tr>
<tr>
<td><b>cp</b></td>
<td>Chest pain type <br> (4 values: 0, 1, 2, 3)</td>
<td>3; 1; 2; ...</td>
</tr>
<tr>
<td><b>trestbps</b></td>
<td>resting blood pressure  <br> (in mm Hg)</td>
<td>145; 130; ...</td>
</tr>
<tr>
<td><b>chol</b></td>
<td>Serum cholestoral <br> (in mg/dl)</td>
<td>233; 250; ...</td>
</tr>
<tr>
<td><b>fbs</b></td>
<td>Fasting blood sugar > 120 mg/dl <br> (1 = true; 0 = false) </td>
<td>1; 0; ...</td>
</tr>
<tr>
<td><b>restecg</b></td>
<td>Resting electrocardiographic results <br> (values 0, 1, 2) </td>
<td>0; 1; ...</td>
</tr>
<tr>
<td><b>thalach</b></td>
<td>Maximum heart rate achieved </td>
<td>150; 187; ...</td>
</tr>
<tr>
<td><b>exang</b></td>
<td>Exercise induced angina <br> (1 = yes; 0 = no) </td>
<td>1; 0; ...</td>
</tr>
<tr>
<td><b>oldpeak</b></td>
<td>ST depression induced by exercise relative to rest</td>
<td>2.3; 3.5; ...</td>
</tr>
<tr>
<td><b>slope</b></td>
<td>The slope of the peak exercise ST segment<br> (values 0, 1, 2) </td>
<td>0; 2; ...</td>
</tr>
<tr>
<td><b>ca</b></td>
<td>number of major vessels (0-4) colored by flourosopy </td>
<td>0; 3; ...</td>
</tr>
<tr>
<td><b>thal</b></td>
<td>(3 = normal; 6 = fixed defect; 7 = reversable defect)</td>
<td>1; 3; ...</td>
</tr>
<tr>
<td><b>Target</b></td>
<td>Target column<br> (1 = Yes; 0 = No) </td>
<td>1; 0; ...</td>
</tr>
</tbody>
</table>
</div>

# Exploratory Data Analysis üåé

## Univariate Analysis

### Age
"""

# --- Variable, Color & Plot Size ---
var = 'age'
fig = plt.figure(figsize=(12, 12))

# --- Skewness & Kurtosis ---
print('\033[1m'+'.: Age Column Skewness & Kurtosis :.'+'\033[0m')
print('*' * 40)
print('Skewness:'+'\033[1m {:.3f}'.format(data[var].skew(axis=0, skipna=True)))
print('\033[0m'+'Kurtosis:'+'\033[1m {:.3f}'.format(data[var].kurt(axis=0, skipna=True)))
print('\n')

# --- General Title ---
fig.suptitle('Age Column Distribution', fontweight='bold', fontsize=16,
             fontfamily='sans-serif')
fig.subplots_adjust(top=0.9)

# --- Histogram ---
ax_1 = fig.add_subplot(2, 2, 2)
plt.title('Histogram Plot', fontweight='bold', fontsize=14,
          fontfamily='sans-serif')
sns.histplot(data=data, x=var, kde=True)
plt.xlabel('Total', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Age', fontweight='regular', fontsize=11, fontfamily='sans-serif')

# --- Q-Q Plot ---
ax_2 = fig.add_subplot(2, 2, 4)
plt.title('Q-Q Plot', fontweight='bold', fontsize=14,
          fontfamily='sans-serif')
qqplot(data[var], fit=True, line='45', ax=ax_2, color='#BA1141')
plt.xlabel('Theoretical Quantiles', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Sample Quantiles', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')

# --- Box Plot ---
ax_3 = fig.add_subplot(1, 2, 1)
plt.title('Box Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
sns.boxplot(data=data, y=var, boxprops=dict(alpha=0.8), linewidth=1.5)
plt.ylabel('Age', fontweight='regular', fontsize=11, fontfamily='sans-serif')

plt.show()

"""<div style="font-family: Segoe UI; line-height: 2; color:#000000 text-align: justify">
    From the <b>histogram and boxplot</b>, it can be seen that this column is <mark><b>normally distributed</b></mark>. This also proven by <b>skewness value (-0.2)</b> of this column.<br>
    In this column, <b>the kurtosis value is -0.5</b>, which indicates that the column is <mark><b>platikurtic</b></mark>.<br>
    From the Q-Q plot, <b>the data values tend to closely follow the 45-degree</b>, which means the data is likely <mark><b>normally distributed</b></mark> (as stated previously).
    <blockquote style="font-size: 12px; color: #000000;"> If skewness is <b>less than -1 or greater than 1</b>, the distribution is <mark><b>highly skewed</b></mark>. If skewness is <b>between -1 and -0.5 or between 0.5 and 1</b>, the distribution is <mark><b>moderately skewed</b></mark>. If skewness is <b>between -0.5 and 0.5</b>, the distribution is <mark><b>approximately symmetric</b></mark>.
    </blockquote>
    <blockquote style="font-size: 12px; color: #000000;">If <mark><b>Kurtosis</b></mark> values are used to show <mark><b>tailedness of a column</b></mark>, the value of a normal distribution (mesokurtotic) should be equal to 3. If kurtosis value is more than 3, it is called leptokurtic. Meanwhile, if kurtosis value is less than 3, then it is called platikurtic.</blockquote>
</div>

### Sex
"""

# --- Setting Labels and Order ---
labels = ['Female', 'Male']
order = data['sex'].value_counts().index

# --- Size for Both Figures ---
plt.figure(figsize=(16, 8))
plt.suptitle('Sex (Gender) Distribution', fontweight='heavy',
             fontsize=16, fontfamily='sans-serif')
plt.figtext(0.5, 0.92, "The distribution of Female patients is higher compared to Male patients",
            ha="center", fontsize=12, fontweight='light', fontfamily='sans-serif')

# --- Pie Chart ---
plt.subplot(1, 2, 1)
plt.title('Pie Chart', fontweight='bold', fontsize=14, fontfamily='sans-serif')
plt.pie(data['sex'].value_counts(), labels=labels, pctdistance=0.7,
        autopct='%.2f%%', wedgeprops=dict(alpha=0.8),
        textprops={'fontsize': 12})
centre = plt.Circle((0, 0), 0.45, fc='white')
plt.gcf().gca().add_artist(centre)

# --- Histogram ---
plt.subplot(1, 2, 2)
plt.title('Histogram', fontweight='bold', fontsize=14, fontfamily='sans-serif')
ax = sns.countplot(x='sex', data=data, order=order, alpha=0.85)
for rect in ax.patches:
    ax.text(rect.get_x() + rect.get_width() / 2,
            rect.get_height() + 4.25,
            rect.get_height(),
            horizontalalignment='center', fontsize=10)

plt.xlabel('Gender', fontweight='bold', fontsize=11, fontfamily='sans-serif')
plt.ylabel('Total', fontweight='bold', fontsize=11, fontfamily='sans-serif')
plt.xticks([0, 1], labels)
plt.grid(axis='y', alpha=0.4)

# --- Count Categorical Labels without Dropping Null Values ---
print('*' * 25)
print('\033[1m'+'.: Sex (Gender) Total :.'+'\033[0m')
print('*' * 25)
print(data['sex'].value_counts(dropna=False))

# Show the plot
plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to avoid overlap with title
plt.show()

"""### Chest Pain (CP)"""

# --- Setting Labels and Order ---
labels = ['Type 0', 'Type 2', 'Type 1', 'Type 3']
order = data['cp'].value_counts().index

# --- Size for Both Figures ---
plt.figure(figsize=(16, 8))
plt.suptitle('Chest Pain Type Distribution', fontweight='heavy', fontsize=16,
             fontfamily='sans-serif')
plt.figtext(0.5, 0.92, "Chest pain type 0 have the highest number compared to other types of chest pain.",
            ha="center", fontsize=12, fontweight='light', fontfamily='sans-serif')


# --- Pie Chart ---
plt.subplot(1, 2, 1)
plt.title('Pie Chart', fontweight='bold', fontsize=14, fontfamily='sans-serif')
plt.pie(data['cp'].value_counts(), labels=labels, pctdistance=0.7,
        autopct='%.2f%%', textprops={'fontsize': 12},
        wedgeprops=dict(alpha=0.8))
centre = plt.Circle((0, 0), 0.45, fc='white')
plt.gcf().gca().add_artist(centre)

# --- Histogram ---
plt.subplot(1, 2, 2)
plt.title('Histogram', fontweight='bold', fontsize=14, fontfamily='sans-serif')
ax = sns.countplot(x='cp', data=data, order=order, alpha=0.85)
for rect in ax.patches:
    ax.text(rect.get_x() + rect.get_width() / 2,
            rect.get_height() + 4.25, rect.get_height(),
            horizontalalignment='center', fontsize=10)

plt.xlabel('Pain Type', fontweight='bold', fontsize=11, fontfamily='sans-serif')
plt.ylabel('Total', fontweight='bold', fontsize=11, fontfamily='sans-serif')
plt.xticks([0, 1, 2, 3], labels)
plt.grid(axis='y', alpha=0.4)

# --- Count Categorical Labels without Dropping Null Values ---
print('*' * 30)
print('\033[1m'+'.: Chest Pain Type Total :.'+'\033[0m')
print('*' * 30)
print(data['cp'].value_counts(dropna=False))

# Show the plot
plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to avoid overlap with the title
plt.show()

"""### trestbps
Resting Blood Pressure (in mm Hg on admission to the hospital)
"""

# --- Setting Labels and Order ---
labels = ['Low', 'Medium-Low', 'Medium-High', 'High']
order = data['trestbps'].value_counts().index

# --- Figure 1: Distribution Visualization ---
plt.figure(figsize=(16, 8))
plt.suptitle('Resting Blood Pressure Distribution', fontweight='heavy', fontsize=16,
             fontfamily='sans-serif')
plt.figtext(0.5, 0.92, "Distribution of resting blood pressure categories.",
            ha="center", fontsize=12, fontweight='light', fontfamily='sans-serif')

# --- Histogram (Numerical Distribution) ---
plt.subplot(1, 2, 1)
plt.title('Histogram', fontweight='bold', fontsize=14, fontfamily='sans-serif')
sns.histplot(data=data, x='trestbps', kde=True)  # Visualize the original numerical data
plt.xlabel('Resting Blood Pressure (mm Hg)', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Frequency', fontweight='regular', fontsize=11, fontfamily='sans-serif')

# --- Box Plot for Relationship with Target ---
plt.subplot(1, 2, 2)
sns.boxplot(x='target', y='trestbps', data=data, palette='coolwarm')
plt.title('Resting Blood Pressure by Heart Disease Target', fontweight='bold',
          fontsize=14, fontfamily='sans-serif')
plt.xlabel('Heart Disease (0 = No, 1 = Yes)', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Resting Blood Pressure (mm Hg)', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')

# --- Adjust Layout ---
plt.tight_layout(rect=[0, 0, 1, 0.95])  # Avoid overlap with the suptitle
plt.show()

# --- Display Value Counts ---
print('*' * 30)
print('\033[1m' + '.: Resting Blood Pressure Total :.' + '\033[0m')
print('*' * 30)
print(data['trestbps'].value_counts(dropna=False))

"""### Cholestrol
Serum cholestoral in mg/dl
"""

# --- Variable & Plot Size ---
var = 'chol'
fig = plt.figure(figsize=(12, 12))

# --- Skewness & Kurtosis ---
print('\033[1m'+'.: Serum Cholestoral Column Skewness & Kurtosis :.'+'\033[0m')
print('*' * 45)
print('Skewness:'+'\033[1m {:.3f}'.format(data[var].skew(axis=0, skipna=True)))
print('\033[0m'+'Kurtosis:'+'\033[1m {:.3f}'.format(data[var].kurt(axis=0, skipna=True)))
print('\n')

# --- General Title ---
fig.suptitle('Serum Cholestoral Column Distribution', fontweight='bold',
             fontsize=16, fontfamily='sans-serif')
fig.subplots_adjust(top=0.9)

# --- Histogram ---
ax_1 = fig.add_subplot(2, 2, 2)
plt.title('Histogram Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
sns.histplot(data=data, x=var, kde=True)
plt.xlabel('Total', fontweight='regular', fontsize=11, fontfamily='sans-serif')
plt.ylabel('Serum Cholestoral', fontweight='regular', fontsize=11, fontfamily='sans-serif')

# --- Q-Q Plot ---
ax_2 = fig.add_subplot(2, 2, 4)
plt.title('Q-Q Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
qqplot(data[var], fit=True, line='45', ax=ax_2, alpha=0.6)
plt.xlabel('Theoretical Quantiles', fontweight='regular', fontsize=11, fontfamily='sans-serif')
plt.ylabel('Sample Quantiles', fontweight='regular', fontsize=11, fontfamily='sans-serif')

# --- Box Plot ---
ax_3 = fig.add_subplot(1, 2, 1)
plt.title('Box Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
sns.boxplot(data=data, y=var, boxprops=dict(alpha=0.8), linewidth=1.5)
plt.ylabel('Serum Cholestoral', fontweight='regular', fontsize=11, fontfamily='sans-serif')

plt.show()

"""### fbs
(fasting blood sugar &gt; 120 mg/dl)
(1 = true; 0 = false)
"""

# --- Setting Labels and Order ---
labels = ['< 120 mg/dl', '> 120 mg/dl']
order = data['fbs'].value_counts().index

# --- Size for Both Figures ---
plt.figure(figsize=(16, 8))
plt.suptitle('Fasting Blood Sugar Distribution', fontweight='heavy',
             fontsize=16, fontfamily='sans-serif')

# --- Pie Chart ---
plt.subplot(1, 2, 1)
plt.title('Pie Chart', fontweight='bold', fontsize=14, fontfamily='sans-serif')
plt.pie(data['fbs'].value_counts(), labels=labels,
        wedgeprops=dict(alpha=0.8), autopct='%.2f%%',
        pctdistance=0.7, textprops={'fontsize': 12})
centre = plt.Circle((0, 0), 0.45, fc='white')
plt.gcf().gca().add_artist(centre)

# --- Histogram ---
countplt = plt.subplot(1, 2, 2)
plt.title('Histogram', fontweight='bold', fontsize=14, fontfamily='sans-serif')
ax = sns.countplot(x='fbs', data=data, order=order, alpha=0.85)
for rect in ax.patches:
    ax.text(rect.get_x() + rect.get_width() / 2,
            rect.get_height() + 4.25, rect.get_height(),
            horizontalalignment='center', fontsize=10)

plt.xlabel('Fasting Blood Sugar', fontweight='bold', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Total', fontweight='bold', fontsize=11, fontfamily='sans-serif')
plt.xticks([0, 1], labels)
plt.grid(axis='y', alpha=0.4)

# --- Count Categorical Labels without Dropping Null Values ---
print('*' * 32)
print('\033[1m'+'.: Fasting Blood Sugar Total :.'+'\033[0m')
print('*' * 32)
print(data.fbs.value_counts(dropna=False))

"""### Restecg
Resting electrocardiographic results
"""

# --- Setting Labels and Order ---
labels = ['1', '0', '2']
order = data['restecg'].value_counts().index

# --- Size for Both Figures ---
plt.figure(figsize=(16, 8))
plt.suptitle('Resting Electrocardiographic Distribution', fontweight='heavy',
             fontsize=16, fontfamily='sans-serif')

# --- Pie Chart ---
plt.subplot(1, 2, 1)
plt.title('Pie Chart', fontweight='bold', fontsize=14, fontfamily='sans-serif')
plt.pie(data['restecg'].value_counts(), labels=labels,
        wedgeprops=dict(alpha=0.8), autopct='%.2f%%',
        pctdistance=0.7, textprops={'fontsize': 12})
centre = plt.Circle((0, 0), 0.45, fc='white')
plt.gcf().gca().add_artist(centre)

# --- Histogram ---
countplt = plt.subplot(1, 2, 2)
plt.title('Histogram', fontweight='bold', fontsize=14, fontfamily='sans-serif')
ax = sns.countplot(x='restecg', data=data, order=order, alpha=0.85)
for rect in ax.patches:
    ax.text(rect.get_x() + rect.get_width() / 2,
            rect.get_height() + 4.25, rect.get_height(),
            horizontalalignment='center', fontsize=10)

plt.xlabel('Resting Electrocardiographic', fontweight='bold', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Total', fontweight='bold', fontsize=11, fontfamily='sans-serif')
plt.grid(axis='y', alpha=0.4)

# --- Count Categorical Labels without Dropping Null Values ---
print('*' * 50)
print('\033[1m'+'.: Resting Electrocardiographic Results Total :.'+'\033[0m')
print('*' * 50)
print(data.restecg.value_counts(dropna=False))

"""### Thalach
Maximum heart rate achieved
"""

# --- Variable & Plot Size ---
var = 'thalach'
fig = plt.figure(figsize=(12, 12))

# --- Skewness & Kurtosis ---
print('\033[1m'+'.: Maximum Heart Rate Column Skewness & Kurtosis :.'+'\033[0m')
print('*' * 50)
print('Skewness:' + '\033[1m {:.3f}'.format(data[var].skew(axis=0, skipna=True)))
print('\033[0m' + 'Kurtosis:' + '\033[1m {:.3f}'.format(data[var].kurt(axis=0, skipna=True)))
print('\n')

# --- General Title ---
fig.suptitle('Maximum Heart Rate Column Distribution', fontweight='bold',
             fontsize=16, fontfamily='sans-serif')
fig.subplots_adjust(top=0.9)

# --- Histogram ---
ax_1 = fig.add_subplot(2, 2, 2)
plt.title('Histogram Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
sns.histplot(data=data, x=var, kde=True)
plt.xlabel('Total', fontweight='regular', fontsize=11, fontfamily='sans-serif')
plt.ylabel('Maximum Heart Rate', fontweight='regular', fontsize=11, fontfamily='sans-serif')

# --- Q-Q Plot ---
ax_2 = fig.add_subplot(2, 2, 4)
plt.title('Q-Q Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
qqplot(data[var], fit=True, line='45', ax=ax_2, markerfacecolor='blue', markeredgecolor='blue', alpha=0.6)
plt.xlabel('Theoretical Quantiles', fontweight='regular', fontsize=11, fontfamily='sans-serif')
plt.ylabel('Sample Quantiles', fontweight='regular', fontsize=11, fontfamily='sans-serif')

# --- Box Plot ---
ax_3 = fig.add_subplot(1, 2, 1)
plt.title('Box Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
sns.boxplot(data=data, y=var, linewidth=1.5)
plt.ylabel('Maximum Heart Rate', fontweight='regular', fontsize=11, fontfamily='sans-serif')

plt.show()

"""### Exang
Exercise Induced Angina
"""

# --- Labels & Order ---
labels = ['False', 'True']
order = data['exang'].value_counts().index

# --- Size for Both Figures ---
plt.figure(figsize=(16, 8))
plt.suptitle('Exercise Induced Angina Distribution', fontweight='heavy',
             fontsize=16, fontfamily='sans-serif')

# --- Pie Chart ---
plt.subplot(1, 2, 1)
plt.title('Pie Chart', fontweight='bold', fontsize=14, fontfamily='sans-serif')
plt.pie(data['exang'].value_counts(), labels=labels,
        wedgeprops=dict(alpha=0.8, edgecolor='black'), autopct='%.2f%%',
        pctdistance=0.7, textprops={'fontsize': 12})
centre = plt.Circle((0, 0), 0.45, fc='white', edgecolor='black')
plt.gcf().gca().add_artist(centre)

# --- Histogram ---
countplt = plt.subplot(1, 2, 2)
plt.title('Histogram', fontweight='bold', fontsize=14, fontfamily='sans-serif')
ax = sns.countplot(x='exang', data=data, order=order, edgecolor='black', alpha=0.85)
for rect in ax.patches:
    ax.text(rect.get_x() + rect.get_width() / 2,
            rect.get_height() + 4.25, rect.get_height(),
            horizontalalignment='center', fontsize=10,
            bbox=dict(facecolor='none', edgecolor='black', linewidth=0.25,
                      boxstyle='round'))

plt.xlabel('Exercise Induced Angina', fontweight='bold', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Total', fontweight='bold', fontsize=11, fontfamily='sans-serif')
plt.xticks([0, 1], labels)
plt.grid(axis='y', alpha=0.4)
countplt

# --- Count Categorical Labels w/out Dropping Null Values ---
print('*' * 35)
print('\033[1m'+'.: Exercise Induced Angina Total :.'+'\033[0m')
print('*' * 35)
print(data['exang'].value_counts(dropna=False))

"""### Oldpeak
ST depression induced by exercise relative to rest
"""

# --- Variable & Plot Size ---
var = 'oldpeak'
fig = plt.figure(figsize=(12, 12))

# --- Skewness & Kurtosis ---
print('\033[1m'+'.: "oldpeak" Column Skewness & Kurtosis :.'+'\033[0m')
print('*' * 40)
print('Skewness:'+'\033[1m {:.3f}'.format(data[var].skew(axis=0, skipna=True)))
print('\033[0m'+'Kurtosis:'+'\033[1m {:.3f}'.format(data[var].kurt(axis=0, skipna=True)))
print('\n')

# --- General Title ---
fig.suptitle('Oldpeak Column Distribution', fontweight='bold',
             fontsize=16, fontfamily='sans-serif')
fig.subplots_adjust(top=0.9)

# --- Histogram ---
ax_1 = fig.add_subplot(2, 2, 2)
plt.title('Histogram Plot', fontweight='bold', fontsize=14,
          fontfamily='sans-serif')
sns.histplot(data=data, x=var, kde=True)
plt.xlabel('Total', fontweight='regular', fontsize=11, fontfamily='sans-serif')
plt.ylabel('oldpeak', fontweight='regular', fontsize=11, fontfamily='sans-serif')

# --- Q-Q Plot ---
ax_2 = fig.add_subplot(2, 2, 4)
plt.title('Q-Q Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
qqplot(data[var], fit=True, line='45', ax=ax_2, alpha=0.6)
plt.xlabel('Theoretical Quantiles', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')
plt.ylabel('Sample Quantiles', fontweight='regular', fontsize=11,
           fontfamily='sans-serif')

# --- Box Plot ---
ax_3 = fig.add_subplot(1, 2, 1)
plt.title('Box Plot', fontweight='bold', fontsize=14, fontfamily='sans-serif')
sns.boxplot(data=data, y=var, linewidth=1.5)
plt.ylabel('oldpeak', fontweight='regular', fontsize=11, fontfamily='sans-serif')

plt.show()

"""## Multivariate Analysis

### Heart Disease Scatter Based on Age
"""

# -- Scatter Plot Size & Titles Settings ---
plt.figure(figsize=(10, 8))
plt.suptitle('Heart Rate Based on Age',
             fontweight='heavy',
             x=0.048,
             y=0.98,
             ha='left',
             fontsize='16',
             fontfamily='sans-serif',
             )
plt.title('Based on age, patients with and without heart diseases mostly between 50-70 years old. Patients with heart diseases tend to have high heart rate\ncompared to patients with no heart diseases.',
          fontsize='8',
          fontfamily='sans-serif',
          loc='left',
          )
plt.tight_layout(rect=[0, 0.04, 1, 1.01])

# --- Creating Scatter Plot ---
plt.scatter(x=data.age[data.target==0], y=data.thalach[(data.target==0)])
plt.scatter(x=data.age[data.target==1], y=data.thalach[(data.target==1)])

# --- Scatter Plot Legend & Labels Settings ---
plt.legend(['False', 'True'],
           title='$\\bf{Type}$',
           fontsize='7',
           title_fontsize='8',
           loc='upper right',
           frameon=True)

plt.xlabel('Age',
           fontweight='bold',
           fontsize='11',
           fontfamily='sans-serif',
           )

plt.ylabel('Max. Heart Rate',
           fontweight='bold',
           fontsize='11',
           fontfamily='sans-serif',
           )

plt.ticklabel_format(style='plain',
                     axis='both')

plt.grid(axis='both',
         alpha=0.4,
         lw=0.5)

plt.show();

"""### Heart Disease Distribution based on Fasting Blood Sugar"""

# --- Labels Settings ---
labels = ['False', 'True']
label_gender = np.array([0, 1])
label_gender2 = ['< 120 mg/dl', '> 120 mg/dl']

# --- Creating Bar Chart ---
ax = pd.crosstab(data.fbs,
                 data.target).plot(kind='bar', figsize=(8, 5),stacked=True, alpha=0.85)

# --- Bar Chart Settings ---
for rect in ax.patches:
    width, height = rect.get_width(), rect.get_height()
    x, y = rect.get_xy()
    ax.text(x + width / 2, y + height / 2, '{:.0f}'.format(height),
            horizontalalignment='center', verticalalignment='center')

# --- Title and Annotations ---
plt.suptitle('Heart Disease Distribution based on Fasting Blood Sugar',
             fontweight='bold', x=0.065, y=0.98, ha='left', fontsize=16)
plt.title('The number of patients with low fasting blood sugar is higher compared to patients with high fasting blood sugar. In low\nfasting blood sugar, patients tend to have heart diseases. Also, the distribution of heart diseases patients with high\nfasting blood sugar is equally distributed.',
          fontsize=8, loc='left')

# --- General Chart Settings ---
plt.tight_layout(rect=[0, 0.04, 1, 1.025])
plt.xlabel('Fasting Blood Sugar', fontweight='bold')
plt.ylabel('Total', fontweight='bold')
plt.xticks(label_gender, label_gender2, rotation=0)
plt.grid(axis='y', alpha=0.4)
plt.grid(axis='x', alpha=0)
plt.legend(labels=labels, title='Target', fontsize=8, title_fontsize=9,
           loc='upper left', frameon=True)

plt.show()

"""### Heatmap Each Variables"""

plt.figure(figsize=(14, 9))

# Select only numerical columns for correlation calculation
numerical_data = data.select_dtypes(include=np.number)

sns.heatmap(numerical_data.corr(),
            annot=True,
            cmap='Reds',
            linewidths=0.1)

plt.suptitle('Correlation Map of Numerical Variables',
             fontweight='heavy',
             x=0.03,
             y=0.98,
             ha='left',
             fontsize='16',
             fontfamily='sans-serif')

plt.title('Resting blood pressure, cholestoral, and "oldpeak" have moderate relationship with age.',
          fontsize='10',
          fontfamily='sans-serif',
          loc='left')

plt.tight_layout(rect=[0,
                       0.04,
                       1,
                       1.01])
plt.show()

"""# Machine Learning Modeling ü§ñ

## Traditional Machine Learning ‚ö°
"""

# Sesuaikan Data Type
categorical_cols = data.select_dtypes(include=['object']).columns.tolist()
numerical_cols = data.select_dtypes(include=['int', 'float']).columns.tolist()

print("Variabel Kategorik :", categorical_cols)

print("Variables Numerik :", numerical_cols)

categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']
numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']

df_processed = data.copy()

label_encoder = LabelEncoder()
df_processed[categorical_cols] = df_processed[categorical_cols].apply(lambda col: label_encoder.fit_transform(col))

#scaler = StandardScaler()
#df_processed[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])

X = df_processed.drop('target', axis=1)
y = df_processed['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)
print(X_train.shape)
print(X_test.shape)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define base models
base_models = [
    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)),
    ('svc', SVC(probability=True, kernel='rbf', C=1.0, gamma='scale', random_state=42)),
    ('knn', KNeighborsClassifier(n_neighbors=5, algorithm='auto', p=2)),  # p=2 for Euclidean distance
    ('log', LogisticRegression(max_iter=2000, C=0.5, solver='lbfgs', random_state=42)),
    ('et', ExtraTreesClassifier(n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)),
    ('dt', DecisionTreeClassifier(max_depth=10, min_samples_split=10, min_samples_leaf=2, random_state=42))
]

# Define meta-model
meta_model = LogisticRegression(max_iter=2000, C=0.5, solver='lbfgs')

# Create stacking classifier
stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)
stacked_model.fit(X_train_scaled, y_train)

# Predict and evaluate the stacked model
y_pred_stacked = stacked_model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred_stacked)
report = classification_report(y_test, y_pred_stacked)

# Output results
print(f"Stacked Model Accuracy: {accuracy:.4f}")
print("\nClassification Report:\n", report)

# Cross-validation scores for base models
for name, model in base_models:
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
    print(f"\n{name} Cross-Validation Scores: {cv_scores}")
    print(f"{name} Mean CV Accuracy: {cv_scores.mean():.4f}")

# Cross-validation scores for stacked model
stacked_cv_scores = cross_val_score(stacked_model, X_train_scaled, y_train, cv=5, scoring='accuracy')
print(f"\nStacked Model Cross-Validation Mean Accuracy: {stacked_cv_scores.mean():.4f}")

from pycaret.classification import *
clf = setup(data = data, target = 'target', session_id=123)

compare_models()

clf = setup(data = data, target = 'target', session_id=123)
lgbm = create_model('et')

# Evaluate the model
evaluate_model(lgbm)
# 'et' (Extra Trees Classifier)
# 'rf' (Random Forest Classifier)
# 'gbc' (Gradient Boosting Classifier)
# 'knn' (K-Nearest Neighbors Classifier)
# 'dt' (Decision Tree Classifier)
# 'nb' (Naive Bayes Classifier)
# 'svm' (Support Vector Machine)
# 'ridge' (Ridge Classifier)

"""## Deep Learning üî•"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.utils import class_weight
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from tensorflow.keras import regularizers


model = keras.Sequential([
    layers.Dense(1024, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(0.5)),  # Input layer with L2 regularization
    layers.Dropout(0.3),
    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.4)),
    layers.Dropout(0.2),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train,
                    y_train,
                    validation_data=(X_test, y_test),
                    epochs=100,
                    batch_size=16,
                    verbose=1, )

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print('Test accuracy:', accuracy)

# Make predictions
predictions = model.predict(X_test)

plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy']) # Changed 'val_acc' to 'val_accuracy'
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.utils import class_weight
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from tensorflow.keras import regularizers


model = keras.Sequential([
    layers.Dense(1024, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(0.5)),  # Input layer with L2 regularization
    layers.Dropout(0.8),
    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.4)),
    layers.Dropout(0.2),
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train,
                    y_train,
                    validation_data=(X_test, y_test),
                    epochs=100,
                    batch_size=16,
                    verbose=1, )

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print('Test accuracy:', accuracy)

# Make predictions
predictions = model.predict(X_test)

plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy']) # Changed 'val_acc' to 'val_accuracy'
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# Initialize the scaler and normalize the training set
scaler = StandardScaler()
X_train_normalized = scaler.fit_transform(X_train)
X_test_normalized = scaler.fit_transform(X_test)

from keras.callbacks import EarlyStopping
es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=15)
model = Sequential()
model.add(Dense(64, input_dim=13, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(32, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(8, activation='relu'))

model.add(Dense(1, activation='sigmoid'))

# compile model
adam = Adam(learning_rate=0.001)
# Change the loss to 'binary_crossentropy'
model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
model.summary()

# fit the model to the test data
history=model.fit(X_train_normalized, y_train, validation_data=(X_test_normalized, y_test),epochs=50, batch_size=64, callbacks=[es])
acc = model.evaluate(X_test_normalized, y_test)
print(f"Loss:      {round(acc[0]*100,2)}%\n")
print(f"Accuracy:  {round(acc[1]*100,2)}%\n")
import matplotlib.pyplot as plt
# %matplotlib inline
# Model accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'])
plt.show()
# Model Losss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'])
plt.show()

# Commented out IPython magic to ensure Python compatibility.
#Improved Deep Learning Model
def create_deep_learning_model(input_shape):
    model = keras.Sequential([
        layers.Dense(512, activation='relu', input_shape=input_shape, kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),  # Add batch normalization
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        #layers.BatchNormalization(),
        #layers.Dropout(0.4),
        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# Standardize data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create and compile the model
model = create_deep_learning_model(input_shape=(X_train_scaled.shape[1],))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train_scaled, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)


# Evaluate the model
loss, accuracy = model.evaluate(X_test_scaled, y_test)
print(f"Deep Learning Model Accuracy: {accuracy * 100:.2f}%")

acc = model.evaluate(X_test_normalized, y_test)
print(f"Loss:      {round(acc[0]*100,2)}%\n")
print(f"Accuracy:  {round(acc[1]*100,2)}%\n")
import matplotlib.pyplot as plt
# %matplotlib inline
# Model accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'])
plt.show()
# Model Losss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'])
plt.show()

def create_and_train_model(X_train, y_train, X_test, y_test, optimizer='adam', learning_rate=0.001, num_layers=3, units_per_layer=64, dropout_rate=0.3, l2_reg=0.001, epochs=100, batch_size=32):

    # Standardize data
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = keras.Sequential()
    model.add(layers.Dense(units_per_layer, activation='relu', input_shape=(X_train_scaled.shape[1],), kernel_regularizer=regularizers.l2(l2_reg)))
    model.add(layers.Dropout(dropout_rate))

    for _ in range(num_layers - 1):
      model.add(layers.Dense(units_per_layer, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))
      model.add(layers.Dropout(dropout_rate))

    model.add(layers.Dense(1, activation='sigmoid'))

    optimizer_instance = Adam(learning_rate=learning_rate) if optimizer=='adam' else optimizer

    model.compile(optimizer=optimizer_instance, loss='binary_crossentropy', metrics=['accuracy'])

    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    history = model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)

    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)
    return model, history, accuracy, loss

# Hyperparameter tuning (example)
best_accuracy = 0
best_params = {}
for learning_rate in [0.001, 0.01]:
    for num_layers in [2, 3]:
        for units_per_layer in [32, 64]:
            for dropout_rate in [0.2, 0.3]:
                for l2_reg in [0.001, 0.01]:
                    model, history, accuracy, loss = create_and_train_model(X_train, y_train, X_test, y_test, learning_rate=learning_rate, num_layers=num_layers, units_per_layer=units_per_layer, dropout_rate=dropout_rate, l2_reg=l2_reg)
                    if accuracy > best_accuracy:
                        best_accuracy = accuracy
                        best_params = {
                            'learning_rate': learning_rate,
                            'num_layers': num_layers,
                            'units_per_layer': units_per_layer,
                            'dropout_rate': dropout_rate,
                            'l2_reg': l2_reg
                        }
                        print("New best accuracy:", accuracy, best_params)


print("Best accuracy:", best_accuracy)
print("Best parameters:", best_params)

"""# **Insights ‚≠ê**"""